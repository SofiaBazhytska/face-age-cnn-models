{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":78156,"sourceType":"datasetVersion","datasetId":44109},{"sourceId":11237969,"sourceType":"datasetVersion","datasetId":7020759},{"sourceId":11377467,"sourceType":"datasetVersion","datasetId":7123279},{"sourceId":11516378,"sourceType":"datasetVersion","datasetId":7222187},{"sourceId":11792874,"sourceType":"datasetVersion","datasetId":7404964},{"sourceId":11809477,"sourceType":"datasetVersion","datasetId":7416932},{"sourceId":11937868,"sourceType":"datasetVersion","datasetId":7505320},{"sourceId":11968156,"sourceType":"datasetVersion","datasetId":7525741},{"sourceId":11980277,"sourceType":"datasetVersion","datasetId":7534415}],"dockerImageVersionId":30918,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D,MaxPooling2D,GlobalAveragePooling2D, Dropout, Flatten, Dense\nfrom keras import regularizers\nfrom keras.optimizers import SGD\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.preprocessing import LabelEncoder\nfrom tensorflow.keras.utils import to_categorical\nimport matplotlib.image as mpimg\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nfrom sklearn.model_selection import train_test_split\nimport cv2\nimport os","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"image_path = '/kaggle/input/utkface-filtered-images'","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Завантаження зображень з папки, попередня обробка та формування набору даних (X — зображення, Y — мітки віку)**","metadata":{}},{"cell_type":"code","source":"width = 100\nheight = 100\n\nX = []\nY = []\n\n# Проходимо по всіх файлах в папці\nfor folder_name, _, filenames in os.walk(image_path):\n    for file in filenames:\n        # Створюємо повний шлях до файлу\n        file_path = os.path.join(folder_name, file)\n        \n        # Отримуємо мітку віку з назви файлу (перша частина до символу '_')\n        age = int(file.split('_')[0]) \n        \n        # Відкриваємо зображення\n        image = Image.open(file_path)\n        image = image.convert('RGB')\n        image = image.resize((width, height))\n        \n        # Додаємо зображення і мітку до відповідних списків\n        X.append(np.array(image))\n        Y.append(age)\n\nX = np.array(X)\nY = np.array(Y)\n\nprint(f\"Зображень: {X.shape[0]}, Міток: {Y.shape[0]}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Нормалізація пікселів зображень до діапазону [0, 1]**","metadata":{}},{"cell_type":"code","source":"X = X.astype('float32')\nX /= 255.0\n\nprint('Min: %.3f, Max: %.3f' % (X.min(), X.max()))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Розбиття даних на тренувальний, валідаційний і тестовий набори з конверсією міток у float32**","metadata":{}},{"cell_type":"code","source":"seed = 42\n# Спочатку 70% train, 30% temp\nX_train, X_temp, Y_train, Y_temp = train_test_split(\n    X, Y,\n    test_size=0.3,\n    random_state=seed,\n    stratify=Y,\n    shuffle=True\n)\n\n# Потім temp (30%) ділимо навпіл: 15% val, 15% test\nX_val, X_test, Y_val, Y_test = train_test_split(\n    X_temp, Y_temp,\n    test_size=0.5,\n    random_state=seed,\n    stratify=Y_temp,\n    shuffle=True\n)\n\n# Приводимо до потрібного типу (якщо треба для моделі)\nY_train = np.array(Y_train, dtype=np.float32)\nY_val = np.array(Y_val, dtype=np.float32)\nY_test = np.array(Y_test, dtype=np.float32)\n\nprint(\"Y_train shape:\", Y_train.shape)\nprint(\"Y_val shape:\", Y_val.shape)\nprint(\"Y_test shape:\", Y_test.shape)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Налаштування генераторів зображень: аугментація для тренувальних, без змін для тестових даних**","metadata":{}},{"cell_type":"code","source":"train_datagen = ImageDataGenerator(\n    shear_range=0.2,\n    zoom_range=0.1,\n    horizontal_flip=True,\n    vertical_flip=True\n)\n\ntest_datagen = ImageDataGenerator()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Налаштування callback-функцій та гіперпараметрів навчання**","metadata":{}},{"cell_type":"code","source":"from keras.callbacks import Callback, ReduceLROnPlateau, EarlyStopping\nfrom timeit import default_timer as timer\n\n# Callback для вимірювання часу тренування кожної епохи\nclass TimingCallback(Callback):\n    def __init__(self):\n        self.logs = []\n\n    def on_epoch_begin(self, epoch, logs=None):\n        self.starttime = timer()\n\n    def on_epoch_end(self, epoch, logs=None):\n        self.logs.append(timer() - self.starttime)\n\n# Callback для ранньої зупинки навчання\nearly_stopping = EarlyStopping(\n    patience=6,  # Чекаємо 6 епох перед зупинкою\n    min_delta=0.01,  # Якщо зміни у втраті менші за 1%, зупиняємось\n    verbose=1,\n    mode='min',\n    monitor='val_loss'\n)\n\n# Callback для зменшення learning rate при плато\nreduce_learning_rate = ReduceLROnPlateau(\n    monitor=\"val_loss\",\n    patience=5,  # Якщо val_loss не покращується 5 епох, зменшуємо lr\n    factor=0.1,  # Зменшуємо learning rate у 10 разів\n    cooldown=4,  # Чекаємо 4 епохи перед повторним зменшенням\n    min_lr=1e-6,  # Мінімальне значення learning rate\n    verbose=1\n)\n\n# Callback для вимірювання часу епох\ntime_callback = TimingCallback()\n\n# Гіперпараметри\nlr = 0.1\nepochs = 30 \nbatch_size = 32\nresults = {}","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Кодування вікових значень у категорії та one-hot представлення**","metadata":{}},{"cell_type":"code","source":"import numpy as np\nfrom tensorflow.keras.utils import to_categorical\n\nY_train_encoded = Y_train.flatten()\nY_val_encoded = Y_val.flatten()\nY_test_encoded = Y_test.flatten()\n\nbins = [0, 9, 20, 26, 34, 45, 60, 100] \n\nY_train_encoded = np.digitize(Y_train_encoded, bins, right=True) - 1\nY_val_encoded = np.digitize(Y_val_encoded, bins, right=True) - 1\nY_test_encoded = np.digitize(Y_test_encoded, bins, right=True) - 1\n\nif np.max(Y_train_encoded) >= 7 or np.max(Y_val_encoded) >= 7 or np.max(Y_test_encoded) >= 7:\n    print(\"Warning: There are values greater than or equal to 7!\")\n\n# Перетворення на one-hot encoding\nY_train_encoded = to_categorical(Y_train_encoded, num_classes=7)\nY_val_encoded = to_categorical(Y_val_encoded, num_classes=7)\nY_test_encoded = to_categorical(Y_test_encoded, num_classes=7)\n\nprint(\"After one-hot encoding - Y_train_encoded shape:\", Y_train_encoded.shape)\nprint(\"After one-hot encoding - Y_val_encoded shape:\", Y_val_encoded.shape)\nprint(\"After one-hot encoding - Y_test_encoded shape:\", Y_test_encoded.shape)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Генератор навчальних даних з аугментацією для регресійної моделі**","metadata":{}},{"cell_type":"code","source":"train_generator = train_datagen.flow(\n    X_train, Y_train,\n    batch_size=batch_size\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Побудова та навчання регресійної моделі на основі MobileNet**","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.applications import MobileNet\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import (BatchNormalization, GlobalAveragePooling2D, \n                                     Dropout, Dense)\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras import regularizers\nfrom sklearn.utils.class_weight import compute_class_weight\nimport pickle\n\ninput_shape = (100, 100)\nbase_mobilenet_model = MobileNet(\n    input_shape=(input_shape[0], input_shape[1], 3),\n    include_top=False,\n    weights=None\n)\n\nmobilenet_model_reg = Sequential([\n    BatchNormalization(input_shape=(input_shape[0], input_shape[1], 3)),\n    base_mobilenet_model,\n    BatchNormalization(),\n    GlobalAveragePooling2D(),\n    Dropout(0.5),\n    Dense(1, activation='linear')\n])\n\nmobilenet_model_reg.compile(\n    optimizer=Adam(),\n    loss='mean_squared_error', \n    metrics=['mae']\n)\n\n# Навчання MobileNet\nmobilenet_model_reg_history = mobilenet_model_reg.fit(\n    train_generator,\n    batch_size=batch_size,\n    epochs=30,\n    validation_data=(X_val, Y_val),\n    callbacks=[reduce_learning_rate, time_callback],\n    verbose=True\n)\n\nmobilenet_model_reg.save(\"mobilenet_age_regression.h5\")\n\nwith open(\"mobilenet_training_reg_history.pkl\", \"wb\") as f:\n    pickle.dump(mobilenet_model_reg_history.history, f)\n\nprint(\"Модель і історія навчання збережені.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Створення і тренування власної згорткової нейронної мережі для задачі регресії**","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, BatchNormalization, GlobalAveragePooling2D, Dense\nfrom tensorflow.keras import regularizers\nfrom tensorflow.keras.optimizers import Adam\nimport pickle\n\ninput_shape = (100, 100, 3)\n\nmodel = Sequential([\n    Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\", input_shape=input_shape,\n           kernel_regularizer=regularizers.l2(1e-5)),\n    BatchNormalization(),\n    MaxPooling2D(pool_size=(2, 2)),\n    Dropout(0.25),\n\n    Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\",\n           kernel_regularizer=regularizers.l2(1e-5)),\n    BatchNormalization(),\n    MaxPooling2D(pool_size=(2, 2)),\n    Dropout(0.25),\n\n    Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\",\n           kernel_regularizer=regularizers.l2(1e-5)),\n    BatchNormalization(),\n    MaxPooling2D(pool_size=(2, 2)),\n    Dropout(0.25),\n\n    GlobalAveragePooling2D(),\n    Dense(64, activation='relu'),\n    Dropout(0.5),\n    Dense(1, activation=\"linear\")\n])\n\nmodel.compile(\n    optimizer=Adam(learning_rate=1e-4),\n    loss=\"mean_squared_error\",\n    metrics=['mean_absolute_error']\n)\n\nmodel_history = model.fit(\n    train_generator,\n    validation_data=(X_val, Y_val),\n    batch_size=batch_size,\n    epochs=30,\n    callbacks=[reduce_learning_rate, time_callback],\n    verbose=True\n)\n\nmodel.save(\"custom_cnn_age_regression.h5\")\n\nwith open(\"custom_cnn_training_history.pkl\", \"wb\") as f:\n    pickle.dump(model_history.history, f)\n\nprint(\"Модель і історія навчання збережені.\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Створення та навчання регресійної моделі на базі VGG16**","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.applications import VGG16\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import (BatchNormalization, GlobalAveragePooling2D, \n                                     Dropout, Dense)\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras import regularizers\nfrom sklearn.utils.class_weight import compute_class_weight\nimport pickle\n\ninput_shape = (100, 100)\nbase_vgg_model = VGG16(\n    input_shape=(input_shape[0], input_shape[1], 3),\n    include_top=False,\n    weights=None\n)\n\nvgg_model_reg = Sequential([\n    BatchNormalization(input_shape=(input_shape[0], input_shape[1], 3)),\n    base_vgg_model,\n    BatchNormalization(),\n    GlobalAveragePooling2D(),\n    Dropout(0.5),\n    Dense(1, activation='linear')\n])\n\nvgg_model_reg.compile(\n    optimizer=Adam(),\n    loss='mean_squared_error',\n    metrics=['mae']\n)\n\nvgg_model_reg_history = vgg_model_reg.fit(\n    train_generator,\n    batch_size=batch_size,\n    epochs=30,\n    validation_data=(X_val, Y_val),\n    callbacks=[reduce_learning_rate, time_callback],\n    verbose=True\n)\n\nvgg_model_reg.save(\"vgg_age_regression.h5\")\n\nwith open(\"vgg_model_reg_history.pkl\", \"wb\") as f:\n    pickle.dump(vgg_model_reg_history.history, f)\n\nprint(\"Модель і історія навчання збережені.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Генератор з аугментацією даних для класифікації**","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\n\ntrain_generator = train_datagen.flow(\n    X_train,\n    Y_train_encoded,\n    batch_size=batch_size,\n    shuffle=True\n)\n\ntrain_dataset = tf.data.Dataset.from_generator(\n    lambda: train_generator,\n    output_signature=(\n        tf.TensorSpec(shape=(None, 150, 150, 3), dtype=tf.float32),\n        tf.TensorSpec(shape=(None, 7), dtype=tf.float32),\n    )\n).repeat()\n\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\naugmented_images, augmented_labels = next(train_generator)\n\nprint(\"Shape:\", augmented_images.shape)\nprint(\"Dtype:\", augmented_images.dtype)\nprint(\"Min:\", np.min(augmented_images))\nprint(\"Max:\", np.max(augmented_images))\n\nplt.figure(figsize=(10,10))\nfor i in range(9):\n    plt.subplot(3,3,i+1)\n    plt.imshow(augmented_images[i]) \n    plt.axis('off')\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Створення та навчання класифікаційної моделі на базі MobileNet**","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.applications import MobileNet\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import (BatchNormalization, GlobalAveragePooling2D, \n                                     Dropout, Dense, Conv2D, MaxPooling2D, Flatten)\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras import regularizers\nfrom sklearn.utils.class_weight import compute_class_weight\n\ninput_shape = (100, 100)\nbase_mobilenet_model = MobileNet(\n    input_shape=(input_shape[0], input_shape[1], 3),\n    include_top=False,\n    weights=None\n)\n\nmobilenet_model_clas = Sequential([\n    BatchNormalization(input_shape=(input_shape[0], input_shape[1], 3)),\n    base_mobilenet_model,\n    BatchNormalization(),\n    GlobalAveragePooling2D(),\n    Dropout(0.5),\n    Dense(7, activation='softmax',kernel_regularizer=regularizers.l2(0.001)) \n])\n\n\nmobilenet_model_clas.compile(\n    optimizer=Adam(),\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\n\nmobilenet_model_clas_history = mobilenet_model_clas.fit(\n    train_dataset,\n    steps_per_epoch=len(X_train) // batch_size,\n    epochs=40,\n    validation_data=(X_val, Y_val_encoded),\n    callbacks=[reduce_learning_rate, time_callback],\n    verbose=True\n)\n\nmobilenet_model_clas.save(\"mobilenet_age_clas.h5\")\n\nimport pickle\n\nwith open(\"mobilenet_model_clas_history.pkl\", \"wb\") as f:\n    pickle.dump(mobilenet_model_clas_history.history, f)\n\nprint(\"Модель і історія навчання збережені.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Обчислення ваг класів для збалансування навчання класифікаційної моделі**","metadata":{}},{"cell_type":"code","source":"from sklearn.utils.class_weight import compute_class_weight\nimport numpy as np\n\ny_train_labels = np.argmax(Y_train_encoded, axis=1)\n\nclass_weights = compute_class_weight(\n    class_weight='balanced',\n    classes=np.unique(y_train_labels),\n    y=y_train_labels\n)\n\nclass_weight_dict = dict(enumerate(class_weights))\n\nprint(\"Class weights:\", class_weight_dict)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Створення та навчання класифікаційної моделі на базі MobileNet із врахуванням ваг класів**","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.applications import MobileNet\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import (BatchNormalization, GlobalAveragePooling2D, \n                                     Dropout, Dense, Conv2D, MaxPooling2D, Flatten)\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras import regularizers\nfrom sklearn.utils.class_weight import compute_class_weight\n\ninput_shape = (100, 100)\nbase_mobilenet_model = MobileNet(\n    input_shape=(input_shape[0], input_shape[1], 3),\n    include_top=False,\n    weights=None\n)\n\nmobilenet_model_clas = Sequential([\n    BatchNormalization(input_shape=(input_shape[0], input_shape[1], 3)),\n    base_mobilenet_model,\n    BatchNormalization(),\n    GlobalAveragePooling2D(),\n    Dropout(0.5),\n    Dense(7, activation='softmax',kernel_regularizer=regularizers.l2(0.001)) \n])\n\nmobilenet_model_clas.compile(\n    optimizer=Adam(),\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\n\nmobilenet_model_clas_history = mobilenet_model_clas.fit(\n    train_generator,\n    epochs=40,\n    validation_data=(X_val, Y_val_encoded),\n    callbacks=[reduce_learning_rate, time_callback],\n    verbose=True,\n    class_weight=class_weight_dict  # ← працює!\n)\n\nmobilenet_model_clas.save(\"mobilenet_clas_regression.h5\")\n\nimport pickle\n\nwith open(\"mobilenet_model_clas_history.pkl\", \"wb\") as f:\n    pickle.dump(mobilenet_model_clas_history.history, f)\n\nprint(\"Модель і історія навчання збережені.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Порівняння ефективності регресійних моделей за MAE**","metadata":{}},{"cell_type":"code","source":"import pickle\n\nwith open('/kaggle/input/vgg-mobinet/vgg_training_history (1).pkl', 'rb') as f:\n    vgg_history = pickle.load(f)\n\nwith open('/kaggle/input/vgg-mobinet/mobilenet_training_history (1).pkl', 'rb') as f:\n    mobilenet_history = pickle.load(f)\n\nwith open('/kaggle/input/custom-simple-model-reg/custom_cnn_training_history.pkl', 'rb') as f:\n    custom_history = pickle.load(f)\nplt.figure(figsize=(12, 6))\n\nplt.grid(True, linestyle='--', alpha=0.5)\n\nplt.plot(vgg_history['mean_absolute_error'], label='vgg_history model_train')\nplt.plot(vgg_history['val_mean_absolute_error'], '--', label='vgg_history model_val')\n\nplt.plot(mobilenet_history['mae'], label='mobilenet_train')\nplt.plot(mobilenet_history['val_mae'], '--', label='mobilenet_val')\n\nplt.plot(custom_history['mean_absolute_error'], label='custom_train')\nplt.plot(custom_history['val_mean_absolute_error'], '--', label='custom_val')\n\nplt.title('Mean Absolute Error')\nplt.legend()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Підсумкові результати моделей за MAE**","metadata":{}},{"cell_type":"code","source":"print(\"=== VGG Model ===\")\nprint(f\"Train MAE (last epoch): {vgg_history['mean_absolute_error'][-1]:.4f}\")\nprint(f\"Val MAE (last epoch):   {vgg_history['val_mean_absolute_error'][-1]:.4f}\")\n\nprint(\"\\n=== MobileNet Model ===\")\nprint(f\"Train MAE (last epoch): {mobilenet_history['mae'][-1]:.4f}\")\nprint(f\"Val MAE (last epoch):   {mobilenet_history['val_mae'][-1]:.4f}\")\n\nprint(\"\\n=== Custom CNN Model ===\")\nprint(f\"Train MAE (last epoch): {custom_history['mean_absolute_error'][-1]:.4f}\")\nprint(f\"Val MAE (last epoch):   {custom_history['val_mean_absolute_error'][-1]:.4f}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Візуалізація роботи регресійної моделі MobileNet на тестових даних**","metadata":{}},{"cell_type":"code","source":"import random\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom tensorflow.keras.models import load_model\nimport pickle\n\nmodel_mobilenet_reg = load_model('/kaggle/input/vgg-mobinet/mobilenet_age_regression (1).h5')\n\nwith open('/kaggle/input/vgg-mobinet/mobilenet_training_history (1).pkl', 'rb') as f:\n    history_mobilenet_reg = pickle.load(f)\n\npredicted_ages = model_mobilenet_reg.predict(X_test).flatten()\n\ntrue_ages = Y_test.flatten()\n\nindices = random.sample(range(len(X_test)), 8)\n\nplt.figure(figsize=(16, 8))\n\nfor i, idx in enumerate(indices):\n    plt.subplot(2, 4, i + 1)\n    plt.imshow(X_test[idx])\n    plt.axis('off')\n    plt.title(f\"True: {int(true_ages[idx])}\\nPred: {int(predicted_ages[idx])}\",\n              color='green' if abs(true_ages[idx] - predicted_ages[idx]) < 5 else 'red')\n\nplt.tight_layout()\nprint(predicted_ages.shape)\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Візуалізація метрик навчання моделі MobileNet для задачі класифікації**","metadata":{}},{"cell_type":"code","source":"\nmodel_mobilenet = load_model('/kaggle/input/mobilet-class-54-150/mobilenet_clas_regression (2).h5')\n\n# Завантаження історії тренування (перевір точну назву файлу!)\nwith open('/kaggle/input/mobilet-class-54-150/mobilenet_model_clas_history.pkl', 'rb') as f:\n    history_mobilenet_clas = pickle.load(f)\n    \n# Отримуємо дані для точності та втрат з історії тренування\ntrain_accuracy = history_mobilenet_clas['accuracy']\nval_accuracy = history_mobilenet_clas['val_accuracy']\ntrain_loss = history_mobilenet_clas['loss']\nval_loss = history_mobilenet_clas['val_loss']\n\nplt.figure(figsize=(10, 10))\n\nplt.subplot(2, 1, 1)\nplt.plot(train_accuracy, label='Тренувальна точність')\nplt.plot(val_accuracy, label='Валідаційна точність')\nplt.title('Точність моделі')\nplt.xlabel('Епохи')\nplt.ylabel('Точність')\nplt.legend()\n\nplt.subplot(2, 1, 2)\nplt.plot(train_loss, label='Train Loss')\nplt.plot(val_loss, label='Validation Loss')\nplt.title('Втрати моделі')\nplt.xlabel('Епохи')\nplt.ylabel('Втрати')\nplt.legend()\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Візуалізація роботи моделі класифікації MobileNet на тестових даних**","metadata":{}},{"cell_type":"code","source":"import random\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom tensorflow.keras.models import load_model\nimport pickle\n\nmodel_mobilenet = load_model('/kaggle/input/mobilenet-class-56/mobilenet_clas_regression (3).h5')\n\nwith open('/kaggle/input/mobilenet-class-56/mobilenet_model_clas_history (1).pkl', 'rb') as f:\n    history_mobilenet_clas = pickle.load(f)\n\npredictions = model_mobilenet.predict(X_test)\n\ntrue_labels = np.argmax(Y_test_encoded, axis=1)\npredicted_labels = np.argmax(predictions, axis=1)\n\nage_bins_labels = [\n    '1–9 років', '10–20 років', '21–26 років', '27–34 років',\n    '35–45 років', '45–60 років', '60–99 років'\n]\n\nindices = random.sample(range(len(X_test)), 8)\n\nplt.figure(figsize=(16, 8))\n\nfor i, idx in enumerate(indices):\n    plt.subplot(2, 4, i + 1)\n    plt.imshow(X_test[idx])\n    plt.axis('off')\n    plt.title(f\"True: {age_bins_labels[true_labels[idx]]}\\nPred: {age_bins_labels[predicted_labels[idx]]}\",\n              color='green' if true_labels[idx] == predicted_labels[idx] else 'red')\n\nplt.tight_layout()\nprint(predictions.shape)  # має бути (кількість_зразків, 7)\nprint(\"Графік зараз з'явиться\")\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Оцінка якості класифікації вікових груп: F1-метрики та візуалізація матриці невідповідностей**","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.models import load_model\nfrom sklearn.metrics import confusion_matrix\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nage_bins_labels = [\n    '1–9', '10–20', '21–26', '27–34',\n    '35–45', '45–60', '60–99'\n]\n\nY_pred = model_mobilenet.predict(X_test)\nY_pred_classes = np.argmax(Y_pred, axis=1)\nY_true = np.argmax(Y_test_encoded, axis=1)\n\nfrom sklearn.metrics import classification_report, f1_score\n\n# Обчислення F1-score\nf1_macro = f1_score(Y_true, Y_pred_classes, average='macro')\nf1_weighted = f1_score(Y_true, Y_pred_classes, average='weighted')\n\nprint(f\"F1-score (macro): {f1_macro:.4f}\")\nprint(f\"F1-score (weighted): {f1_weighted:.4f}\")\n\nconf_matrix = confusion_matrix(Y_true, Y_pred_classes)\n\nconf_matrix_percent = conf_matrix.astype('float') / conf_matrix.sum(axis=1)[:, np.newaxis] * 100\n\nplt.figure(figsize=(8, 6))\nsns.heatmap(conf_matrix_percent, annot=True, fmt='.1f', cmap='Blues', \n            xticklabels=age_bins_labels, yticklabels=age_bins_labels)\n\nplt.xlabel('Прогнозовані мітки')\nplt.ylabel('Істинні мітки')\nplt.title('Матриця невідповідностей (%)')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Візуалізація метрик навчання моделі MobileNet для задачі класифікації із застосуванням балансування класів**","metadata":{}},{"cell_type":"code","source":"import random\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom tensorflow.keras.models import load_model\nimport pickle\nmodel_mobilenet_balanced = load_model('/kaggle/input/mobilenet-class-56/mobilenet_clas_regression (3).h5')\n\nwith open('/kaggle/input/mobilenet-class-56/mobilenet_model_clas_history (1).pkl', 'rb') as f:\n    history_mobilenet_clas_balanced = pickle.load(f)\n    \ntrain_accuracy = history_mobilenet_clas_balanced['accuracy']\nval_accuracy = history_mobilenet_clas_balanced['val_accuracy']\ntrain_loss = history_mobilenet_clas_balanced['loss']\nval_loss = history_mobilenet_clas_balanced['val_loss']\n\nplt.figure(figsize=(10, 10))\n\nplt.subplot(2, 1, 1)\nplt.plot(train_accuracy, label='Тренувальна точність')\nplt.plot(val_accuracy, label='Валідаційна точність')\nplt.title('Точність моделі')\nplt.xlabel('Епохи')\nplt.ylabel('Точність')\nplt.legend()\n\nplt.subplot(2, 1, 2)\nplt.plot(train_loss, label='Train Loss')\nplt.plot(val_loss, label='Validation Loss')\nplt.title('Втрати моделі')\nplt.xlabel('Епохи')\nplt.ylabel('Втрати')\nplt.legend()\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Оцінка якості класифікації вікових груп після балансування: F1-метрики та візуалізація матриці невідповідностей**","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.models import load_model\nfrom sklearn.metrics import confusion_matrix\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nage_bins_labels = [\n    '1–9', '10–20', '21–26', '27–34',\n    '35–45', '45–60', '60–99'\n]\n\nY_pred = model_mobilenet_balanced.predict(X_test)\nY_pred_classes = np.argmax(Y_pred, axis=1)\nY_true = np.argmax(Y_test_encoded, axis=1)\n\nfrom sklearn.metrics import classification_report, f1_score\n\n# Обчислення F1-score\nf1_macro = f1_score(Y_true, Y_pred_classes, average='macro')\nf1_weighted = f1_score(Y_true, Y_pred_classes, average='weighted')\n\nprint(f\"F1-score (macro): {f1_macro:.4f}\")\nprint(f\"F1-score (weighted): {f1_weighted:.4f}\")\n\nconf_matrix = confusion_matrix(Y_true, Y_pred_classes)\n\nconf_matrix_percent = conf_matrix.astype('float') / conf_matrix.sum(axis=1)[:, np.newaxis] * 100\n\nplt.figure(figsize=(8, 6))\nsns.heatmap(conf_matrix_percent, annot=True, fmt='.1f', cmap='Blues', xticklabels=age_bins_labels, \n            yticklabels=age_bins_labels)\n\nplt.xlabel('Прогнозовані мітки')\nplt.ylabel('Істинні мітки')\nplt.title('Матриця невідповідностей (%)')\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}